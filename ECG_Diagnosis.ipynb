{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ECG Diagnosis Code**\n",
    "\n",
    "This code is based on the code developed here: https://doi.org/10.1038/s41467-020-15432-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization, Activation, Add, Flatten, Dense)\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, TensorBoard, ReduceLROnPlateau,\n",
    "                                        CSVLogger, EarlyStopping)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, classification_report\n",
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessLabels(data_info: pd.DataFrame, train_ids: np.ndarray):\n",
    "    abnormalities = ['1dAVb', 'AF', 'LBBB', 'RBBB', 'SB', 'ST']\n",
    "    good_rows = []\n",
    "    bad_rows = []\n",
    "    labels = np.array([])\n",
    "    for ii, id in enumerate(train_ids):\n",
    "        if id in data_info['exam_id'].to_numpy():\n",
    "            good_rows.append(ii)\n",
    "            data_row = data_info.iloc[np.where(data_info['exam_id'].to_numpy() == id)[0][0]]\n",
    "            labels = np.append(labels, data_row[abnormalities].values.tolist())\n",
    "        else:\n",
    "            bad_rows.append(ii)\n",
    "\n",
    "    labels = np.reshape(labels, (len(good_rows), len(abnormalities)))\n",
    "    \n",
    "    return labels.astype('int64'), good_rows\n",
    "\n",
    "#Load in training data\n",
    "path_to_hdf5 = cwd + '\\\\data\\\\train\\\\exams_part17.hdf5'\n",
    "dataset_name = 'tracings'\n",
    "path_to_csv = cwd + '\\\\data\\\\train\\\\exams.csv'\n",
    "\n",
    "#Process the exams data\n",
    "f = h5py.File(path_to_hdf5, \"r\")\n",
    "tracings_train = f[dataset_name][()]\n",
    "train_ids = f['exam_id'][()]\n",
    "f.close()\n",
    "labels_train, good_rows = ProcessLabels(pd.read_csv(path_to_csv), train_ids)\n",
    "tracings_train = tracings_train[good_rows]\n",
    "\n",
    "#Load in test data\n",
    "path_to_hdf5 = cwd + '\\\\data\\\\test\\\\ecg_tracings.hdf5'\n",
    "dataset_name = 'tracings'\n",
    "path_to_csv = cwd + '\\\\data\\\\test\\\\gold_standard.csv'\n",
    "\n",
    "labels_test = pd.read_csv(path_to_csv).values\n",
    "f = h5py.File(path_to_hdf5, \"r\")\n",
    "tracings_test = f[dataset_name][()]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(object):\n",
    "    def __init__(self, n_samples_out, n_filters_out, kernel_initializer='he_normal',\n",
    "                 dropout_keep_prob=0.8, kernel_size=17, preactivation=True,\n",
    "                 postactivation_bn=False, activation_function='relu'):\n",
    "        self.n_samples_out = n_samples_out\n",
    "        self.n_filters_out = n_filters_out\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.dropout_rate = 1 - dropout_keep_prob\n",
    "        self.kernel_size = kernel_size\n",
    "        self.preactivation = preactivation\n",
    "        self.postactivation_bn = postactivation_bn\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def _skip_connection(self, y, downsample, n_filters_in):\n",
    "        \"\"\"Implement skip connection.\"\"\"\n",
    "        # Deal with downsampling\n",
    "        if downsample > 1:\n",
    "            y = MaxPooling1D(downsample, strides=downsample, padding='same')(y)\n",
    "        elif downsample == 1:\n",
    "            y = y\n",
    "        else:\n",
    "            raise ValueError(\"Number of samples should always decrease.\")\n",
    "        # Deal with n_filters dimension increase\n",
    "        if n_filters_in != self.n_filters_out:\n",
    "            # This is one of the two alternatives presented in ResNet paper\n",
    "            # Other option is to just fill the matrix with zeros.\n",
    "            y = Conv1D(self.n_filters_out, 1, padding='same',\n",
    "                       use_bias=False, kernel_initializer=self.kernel_initializer)(y)\n",
    "        return y\n",
    "\n",
    "    def _batch_norm_plus_activation(self, x):\n",
    "        if self.postactivation_bn:\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            x = BatchNormalization(center=False, scale=False)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(self.activation_function)(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"Residual unit.\"\"\"\n",
    "        x, y = inputs\n",
    "        n_samples_in = y.shape[1]\n",
    "        downsample = n_samples_in // self.n_samples_out\n",
    "        n_filters_in = y.shape[2]\n",
    "        y = self._skip_connection(y, downsample, n_filters_in)\n",
    "        # 1st layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, padding='same',\n",
    "                   use_bias=False, kernel_initializer=self.kernel_initializer)(x)\n",
    "        x = self._batch_norm_plus_activation(x)\n",
    "        if self.dropout_rate > 0:\n",
    "            x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # 2nd layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, strides=downsample,\n",
    "                   padding='same', use_bias=False,\n",
    "                   kernel_initializer=self.kernel_initializer)(x)\n",
    "        if self.preactivation:\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            y = x\n",
    "            x = self._batch_norm_plus_activation(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "            y = x\n",
    "        return [x, y]\n",
    "\n",
    "\n",
    "def get_model(n_classes, last_layer='sigmoid'):\n",
    "    kernel_size = 16\n",
    "    kernel_initializer = 'he_normal'\n",
    "    signal = Input(shape=(4096, 12), dtype=np.float32, name='signal')\n",
    "    x = signal\n",
    "    x = Conv1D(64, kernel_size, padding='same', use_bias=False,\n",
    "               kernel_initializer=kernel_initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x, y = ResidualUnit(1024, 128, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, x])\n",
    "    x, y = ResidualUnit(256, 196, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, y])\n",
    "    x, y = ResidualUnit(64, 256, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, y])\n",
    "    x, _ = ResidualUnit(16, 320, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, y])\n",
    "    x = Flatten()(x)\n",
    "    diagn = Dense(n_classes, activation=last_layer, kernel_initializer=kernel_initializer)(x)\n",
    "    model = Model(signal, diagn)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Parameters**\n",
    "\n",
    "Loading the parameters for the model that were found in the paper. We will call this our first model\n",
    "\n",
    "They trained 10 NN with different initializations. The choose the model to use based on the median micro average persion (mAP = 0.951). They had to choose the one right above the median since 10 is even so they can't take the median execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = cwd + '\\\\model\\\\model.hdf5'\n",
    "\n",
    "loss = 'binary_crossentropy'\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "opt = Adam(lr)\n",
    "\n",
    "model_1 = load_model(path_to_model, compile=False)\n",
    "model_1.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Fromatting**\n",
    "\n",
    "Here is the class for transforming the data into the proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGSequence(Sequence):\n",
    "    @classmethod\n",
    "    def get_seq(cls, tracings: np.ndarray, labels: np.ndarray=None, batch_size=8):\n",
    "        train_seq = cls(tracings, labels, batch_size)\n",
    "        return train_seq\n",
    "\n",
    "    def __init__(self, tracings:np.ndarray, labels:np.ndarray=None, batch_size:int=8):\n",
    "        if labels is None:\n",
    "            self.y = None\n",
    "        else:\n",
    "            self.y = labels\n",
    "        # Get tracings\n",
    "        self.x = tracings\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_count = tracings.shape[0]\n",
    "\n",
    "    @property\n",
    "    def n_classes(self):\n",
    "        return self.y.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "        if self.y is None:\n",
    "            return np.array(self.x[start:end, :, :])\n",
    "        else:\n",
    "            return np.array(self.x[start:end, :, :]), np.array(self.y[start:end])\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(self.sample_count / self.batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Function**\n",
    "\n",
    "We will also train the model with the data accessible for better comparison with the simplified model. We will call this the second model\n",
    "\n",
    "For sake of computational resources and time, the second model was only trained once instead of trained 10 times and then taking the model based on the median mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN:\n",
    "    def __init__(self, loss, opt, verbose):\n",
    "        # Optimization settings\n",
    "        self.callbacks = [ReduceLROnPlateau(monitor='val_loss',\n",
    "                            factor=0.1,\n",
    "                            patience=7,\n",
    "                            min_lr=lr / 100),\n",
    "                            EarlyStopping(monitor='val_loss', \n",
    "                            patience=9,  # Patience should be larger than the one in ReduceLROnPlateau\n",
    "                            min_delta=0.00001)]\n",
    "\n",
    "        self.loss = loss\n",
    "        self.optimizer = opt\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Save the BEST and LAST model\n",
    "        '''callbacks += [ModelCheckpoint('./backup_model_last.hdf5'),\n",
    "        ModelCheckpoint('./backup_model_best.hdf5', save_best_only=True)]'''\n",
    "\n",
    "    def train(self, train_seq, val_seq):\n",
    "        self.model = get_model(train_seq.n_classes)\n",
    "        self.model.compile(loss=self.loss, optimizer=self.optimizer)\n",
    "        # Train neural network\n",
    "        self.model.fit(train_seq,\n",
    "            epochs=70,\n",
    "            initial_epoch=0,  # If you are continuing a interrupted section change here\n",
    "            callbacks=self.callbacks,\n",
    "            validation_data=val_seq,\n",
    "            verbose=self.verbose)\n",
    "\n",
    "    def predict(self, test_seq):\n",
    "        return self.model.predict(test_seq,  verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Models\n",
    "\n",
    "Need to choose what model I want\n",
    "\n",
    "Going to have to use something like random forest because I need a multi-label classifier, or I can use sklearn.multioutput.MultiOutputClassifier and use any classifier\n",
    "\n",
    "I think all of the data for all 12 leads is the set of features for each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Tune the hyperparameters\n",
    "class RF_Model:\n",
    "    def __init__(self, verbose = 1):\n",
    "        self.model = RandomForestClassifier(verbose=verbose)\n",
    "\n",
    "    def train(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.model.fit(X,y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "class LR_model:\n",
    "    def __init__(self, verbose = 1):\n",
    "        self.model = MultiOutputClassifier(LogisticRegression(verbose=verbose))\n",
    "\n",
    "    def train(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Fromatting**\n",
    "\n",
    "PCA for the simplified models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA_Transform:\n",
    "    def __init__(self, r:int):\n",
    "        self.PCA_instance = PCA(n_components=r)\n",
    "    \n",
    "    def _flattenData(self, X:np.ndarray):\n",
    "        return np.hstack(X)\n",
    "\n",
    "    def _processData(self, X: np.ndarray):\n",
    "        X_flat = self._flattenData(X)\n",
    "        self.preprocess = StandardScaler()\n",
    "        self.preprocess.fit(X_flat)\n",
    "\n",
    "    def FitData(self, X: np.ndarray):\n",
    "        self._processData(X)\n",
    "        self.PCA_instance.fit(self.preprocess.transform(self._flattenData(X)))\n",
    "\n",
    "    def TransformData(self, X_train: np.ndarray, X_test: np.ndarray):\n",
    "        X_train = self.preprocess.transform(self._flattenData(X_train))\n",
    "        X_test = self.preprocess.transform(self._flattenData(X_test))\n",
    "        return self.PCA_instance.transform(X_train), self.PCA_instance.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold\n",
    "\n",
    "K-fold procedure for validation of the models\n",
    "\n",
    "They use a validation set of 2% so something to think about\n",
    "\n",
    "They didn't round for the outputs, seems to be a threshold in which they consider it to occur\n",
    "\n",
    "They used precision-recall curves for things, but in total found precision, recall, specificity and F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics Function**\n",
    "\n",
    "Making a function to be able to call all of the metrics each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'Precision': {'Model_1': np.array([]), 'Model_2': np.array([]), 'Model_3': np.array([])},\\\n",
    "        'Recall': {'Model_1': np.array([]), 'Model_2': np.array([]), 'Model_3': np.array([])},\\\n",
    "        'F1': {'Model_1': np.array([]), 'Model_2': np.array([]), 'Model_3': np.array([])}}\n",
    "\n",
    "#TODO: Add specificity and add the ability to pull these for each class, maybe can just make an index and label encoder for the metrics\n",
    "#with each numpy array being 2d\n",
    "def Find_metrics(metrics: dict, model_name: str, y_true: np.ndarray, y_pred: np.ndarray):\n",
    "        metrics['Precision'][model_name] = np.append(metrics['Precision'][model_name], precision_score(y_true, y_pred, average=None))\n",
    "        metrics['Recall'][model_name] = np.append(metrics['Recall'][model_name], recall_score(y_true, y_pred, average=None))\n",
    "        metrics['F1'][model_name] = np.append(metrics['F1'][model_name], f1_score(y_true, y_pred, average=None))\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------Training model 2----------------------\n",
      "Epoch 1/70\n",
      "21/61 [=========>....................] - ETA: 2:10 - loss: 0.1735"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\EDITH\\OneDrive - University of Waterloo\\School\\Masters\\Classes\\SYDE 675\\Project\\SYDE675_project\\ECG_Diagnosis.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000023?line=27'>28</a>\u001b[0m \u001b[39m#Train models\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000023?line=28'>29</a>\u001b[0m \u001b[39m#Here the validation seq is just the test seq since we are using a k-fold analysis\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000023?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------Training model 2----------------------\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000023?line=30'>31</a>\u001b[0m model_2\u001b[39m.\u001b[39;49mtrain(train_seq, val_seq\u001b[39m=\u001b[39;49mtest_seq)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000023?line=31'>32</a>\u001b[0m \u001b[39m'''print('\\n-------------------Training model 3----------------------')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000023?line=32'>33</a>\u001b[0m \u001b[39mmodel_3.train(X = PCA_X_train, y = y_train)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000023?line=33'>34</a>\u001b[0m \u001b[39mprint('\\n-------------------Training model 4----------------------')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000023?line=34'>35</a>\u001b[0m \u001b[39mmodel_4.train(X = PCA_X_train, y = y_train)'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000023?line=36'>37</a>\u001b[0m \u001b[39m#Test models\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\EDITH\\OneDrive - University of Waterloo\\School\\Masters\\Classes\\SYDE 675\\Project\\SYDE675_project\\ECG_Diagnosis.ipynb Cell 15'\u001b[0m in \u001b[0;36mMyCNN.train\u001b[1;34m(self, train_seq, val_seq)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000014?line=21'>22</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss, optimizer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000014?line=22'>23</a>\u001b[0m \u001b[39m# Train neural network\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000014?line=23'>24</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(train_seq,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000014?line=24'>25</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m70\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000014?line=25'>26</a>\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,  \u001b[39m# If you are continuing a interrupted section change here\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000014?line=26'>27</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000014?line=27'>28</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_seq,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis.ipynb#ch0000014?line=28'>29</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:66\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=63'>64</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_method_wrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=64'>65</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_multi_worker_mode():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=65'>66</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=67'>68</a>\u001b[0m   \u001b[39m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=68'>69</a>\u001b[0m   \u001b[39mif\u001b[39;00m dc_context\u001b[39m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:848\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=840'>841</a>\u001b[0m \u001b[39mwith\u001b[39;00m traceme\u001b[39m.\u001b[39mTraceMe(\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=841'>842</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTraceContext\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=842'>843</a>\u001b[0m     graph_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=843'>844</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=844'>845</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=845'>846</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=846'>847</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=847'>848</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m train_function(iterator)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=848'>849</a>\u001b[0m   \u001b[39m# Catch OutOfRangeError for Datasets of unknown size.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=849'>850</a>\u001b[0m   \u001b[39m# This blocks until the batch has finished executing.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=850'>851</a>\u001b[0m   \u001b[39m# TODO(b/150292341): Allow multiple async steps here.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=851'>852</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data_handler\u001b[39m.\u001b[39minferred_steps:\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:580\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=577'>578</a>\u001b[0m     xla_context\u001b[39m.\u001b[39mExit()\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=578'>579</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=579'>580</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=581'>582</a>\u001b[0m \u001b[39mif\u001b[39;00m tracing_count \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tracing_count():\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=582'>583</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_counter\u001b[39m.\u001b[39mcalled_without_tracing()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:611\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=607'>608</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=608'>609</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=609'>610</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=610'>611</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=611'>612</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=612'>613</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=613'>614</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=614'>615</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2420\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=2417'>2418</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=2418'>2419</a>\u001b[0m   graph_function, args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=2419'>2420</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_filtered_call(args, kwargs)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1661\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1646'>1647</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_filtered_call\u001b[39m(\u001b[39mself\u001b[39m, args, kwargs):\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1647'>1648</a>\u001b[0m   \u001b[39m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1648'>1649</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1649'>1650</a>\u001b[0m \u001b[39m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1658'>1659</a>\u001b[0m \u001b[39m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1659'>1660</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1660'>1661</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1661'>1662</a>\u001b[0m       (t \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m nest\u001b[39m.\u001b[39;49mflatten((args, kwargs), expand_composites\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1662'>1663</a>\u001b[0m        \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(t, (ops\u001b[39m.\u001b[39;49mTensor,\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1663'>1664</a>\u001b[0m                          resource_variable_ops\u001b[39m.\u001b[39;49mBaseResourceVariable))),\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1664'>1665</a>\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1739'>1740</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m (\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1740'>1741</a>\u001b[0m     pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1741'>1742</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1742'>1743</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1743'>1744</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1744'>1745</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1745'>1746</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1746'>1747</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1747'>1748</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1748'>1749</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1749'>1750</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1750'>1751</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:593\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=590'>591</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=591'>592</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=592'>593</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=593'>594</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=594'>595</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=600'>601</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=601'>602</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=604'>605</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=605'>606</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "#Initilaize the models that need to be trained\n",
    "model_2 = MyCNN(loss, opt, verbose = 1)\n",
    "'''model_3 = RF_Model(verbose = 1)\n",
    "model_4 = LR_model(verbose = 1)'''\n",
    "\n",
    "#PCA initlization\n",
    "'''PCA_transformer = PCA_Transform(r = 60)'''\n",
    "\n",
    "for train_index, test_index in kf.split(X = tracings_train[:,1,1], y = labels_train):\n",
    "\n",
    "        X_train, X_test = tracings_train[train_index,:,:], tracings_train[test_index,:,:]\n",
    "        y_train, y_test = labels_train[train_index], labels_train[test_index]\n",
    "\n",
    "\n",
    "        #Put data in sequence for models 1 and 2 (CNN)\n",
    "        train_seq = ECGSequence.get_seq(\n",
    "                X_train, y_train, batch_size=64)\n",
    "\n",
    "        test_seq = ECGSequence.get_seq(\n",
    "                X_test, y_test, batch_size=64)\n",
    "\n",
    "        #Transform data with PCA for models 3 and 4\n",
    "        '''PCA_transformer.FitData(X_train)\n",
    "        PCA_X_train, PCA_X_test = PCA_transformer.TransformData(X_train, X_test)'''\n",
    "\n",
    "        #Train models\n",
    "        #Here the validation seq is just the test seq since we are using a k-fold analysis\n",
    "        print('\\n-------------------Training model 2----------------------')\n",
    "        model_2.train(train_seq, val_seq=test_seq)\n",
    "        '''print('\\n-------------------Training model 3----------------------')\n",
    "        model_3.train(X = PCA_X_train, y = y_train)\n",
    "        print('\\n-------------------Training model 4----------------------')\n",
    "        model_4.train(X = PCA_X_train, y = y_train)'''\n",
    "\n",
    "        #Test models\n",
    "        print('\\n-------------------Testing model 1----------------------')\n",
    "        model_1_predict = model_1.predict(test_seq)\n",
    "        print('\\n-------------------Testing model 2----------------------')\n",
    "        model_2_predict = model_2.predict(test_seq)\n",
    "        '''print('\\n-------------------Testing model 3----------------------')\n",
    "        model_3_predict = model_3.predict(PCA_X_train)\n",
    "        print('\\n-------------------Testing model 4----------------------')\n",
    "        model_4_predict = model_4.predict(PCA_X_train)'''\n",
    "\n",
    "        \n",
    "\n",
    "        #Find metrics\n",
    "        #Call the function each time and then can average for each class after\n",
    "\n",
    "        metrics = Find_metrics(metrics, 'Model_1', y_test, model_1_predict)\n",
    "        metrics = Find_metrics(metrics, 'Model_2', y_test, model_2_predict)\n",
    "        '''metrics = Find_metrics(metrics, 'Model_3', y_test, model_3_predict)\n",
    "        metrics = Find_metrics(metrics, 'Model_3', y_test, model_3_predict)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Models**\n",
    "\n",
    "Train all the models that need to be trained on the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Models**\n",
    "\n",
    "Test all the models with the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
