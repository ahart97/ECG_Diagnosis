{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ECG Diagnosis Code**\n",
    "\n",
    "This code is based on the code developed here: https://doi.org/10.1038/s41467-020-15432-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, MaxPooling1D, Dropout, BatchNormalization, Activation, Add, Flatten, Dense)\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, TensorBoard, ReduceLROnPlateau,\n",
    "                                        CSVLogger, EarlyStopping)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EDITH\\AppData\\Local\\Temp\\ipykernel_23872\\1290185358.py:7: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  tracings = f[dataset_name].value\n"
     ]
    }
   ],
   "source": [
    "path_to_hdf5 = cwd + '\\\\data\\\\ecg_tracings.hdf5'\n",
    "dataset_name = 'tracings'\n",
    "path_to_csv = cwd + '\\\\data\\\\gold_standard.csv'\n",
    "\n",
    "labels = pd.read_csv(path_to_csv).values\n",
    "f = h5py.File(path_to_hdf5, \"r\")\n",
    "tracings = f[dataset_name].value\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the NN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(object):\n",
    "    def __init__(self, n_samples_out, n_filters_out, kernel_initializer='he_normal',\n",
    "                 dropout_keep_prob=0.8, kernel_size=17, preactivation=True,\n",
    "                 postactivation_bn=False, activation_function='relu'):\n",
    "        self.n_samples_out = n_samples_out\n",
    "        self.n_filters_out = n_filters_out\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.dropout_rate = 1 - dropout_keep_prob\n",
    "        self.kernel_size = kernel_size\n",
    "        self.preactivation = preactivation\n",
    "        self.postactivation_bn = postactivation_bn\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def _skip_connection(self, y, downsample, n_filters_in):\n",
    "        \"\"\"Implement skip connection.\"\"\"\n",
    "        # Deal with downsampling\n",
    "        if downsample > 1:\n",
    "            y = MaxPooling1D(downsample, strides=downsample, padding='same')(y)\n",
    "        elif downsample == 1:\n",
    "            y = y\n",
    "        else:\n",
    "            raise ValueError(\"Number of samples should always decrease.\")\n",
    "        # Deal with n_filters dimension increase\n",
    "        if n_filters_in != self.n_filters_out:\n",
    "            # This is one of the two alternatives presented in ResNet paper\n",
    "            # Other option is to just fill the matrix with zeros.\n",
    "            y = Conv1D(self.n_filters_out, 1, padding='same',\n",
    "                       use_bias=False, kernel_initializer=self.kernel_initializer)(y)\n",
    "        return y\n",
    "\n",
    "    def _batch_norm_plus_activation(self, x):\n",
    "        if self.postactivation_bn:\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            x = BatchNormalization(center=False, scale=False)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(self.activation_function)(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"Residual unit.\"\"\"\n",
    "        x, y = inputs\n",
    "        n_samples_in = y.shape[1]\n",
    "        downsample = n_samples_in // self.n_samples_out\n",
    "        n_filters_in = y.shape[2]\n",
    "        y = self._skip_connection(y, downsample, n_filters_in)\n",
    "        # 1st layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, padding='same',\n",
    "                   use_bias=False, kernel_initializer=self.kernel_initializer)(x)\n",
    "        x = self._batch_norm_plus_activation(x)\n",
    "        if self.dropout_rate > 0:\n",
    "            x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # 2nd layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, strides=downsample,\n",
    "                   padding='same', use_bias=False,\n",
    "                   kernel_initializer=self.kernel_initializer)(x)\n",
    "        if self.preactivation:\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            y = x\n",
    "            x = self._batch_norm_plus_activation(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "            y = x\n",
    "        return [x, y]\n",
    "\n",
    "\n",
    "def get_model(n_classes, last_layer='sigmoid'):\n",
    "    kernel_size = 16\n",
    "    kernel_initializer = 'he_normal'\n",
    "    signal = Input(shape=(4096, 12), dtype=np.float32, name='signal')\n",
    "    x = signal\n",
    "    x = Conv1D(64, kernel_size, padding='same', use_bias=False,\n",
    "               kernel_initializer=kernel_initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x, y = ResidualUnit(1024, 128, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, x])\n",
    "    x, y = ResidualUnit(256, 196, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, y])\n",
    "    x, y = ResidualUnit(64, 256, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, y])\n",
    "    x, _ = ResidualUnit(16, 320, kernel_size=kernel_size,\n",
    "                        kernel_initializer=kernel_initializer)([x, y])\n",
    "    x = Flatten()(x)\n",
    "    diagn = Dense(n_classes, activation=last_layer, kernel_initializer=kernel_initializer)(x)\n",
    "    model = Model(signal, diagn)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Parameters**\n",
    "\n",
    "Loading the parameters for the model that were found in the paper. We will call this our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 11 so need to figure out which one to use\n",
    "path_to_model = cwd + '\\\\model\\\\model.hdf5'\n",
    "\n",
    "loss = 'binary_crossentropy'\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "opt = Adam(lr)\n",
    "\n",
    "model_1 = load_model(path_to_model, compile=False)\n",
    "model_1.compile(loss=loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data (Make My own for my purposes)**\n",
    "\n",
    "Don't have acess to all data (can only access 15%), so will break the data had into a train and validation set for better comparison with the simplified model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGSequence(Sequence):\n",
    "    @classmethod\n",
    "    def get_seq(cls, tracings: np.ndarray, labels: np.ndarray=None, batch_size=8):\n",
    "        train_seq = cls(tracings, labels, batch_size)\n",
    "        return train_seq\n",
    "\n",
    "    def __init__(self, tracings:np.ndarray, labels:np.ndarray=None, batch_size:int=8):\n",
    "        if labels is None:\n",
    "            self.y = None\n",
    "        else:\n",
    "            self.y = labels\n",
    "        # Get tracings\n",
    "        self.x = tracings\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_count = tracings.shape[0]\n",
    "\n",
    "    @property\n",
    "    def n_classes(self):\n",
    "        return self.y.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "        if self.y is None:\n",
    "            return np.array(self.x[start:end, :, :])\n",
    "        else:\n",
    "            return np.array(self.x[start:end, :, :]), np.array(self.y[start:end])\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(self.sample_count / self.batch_size)\n",
    "\n",
    "#Make a new sequence that just takes in data in an array and puts it into a sequence\n",
    "#This way I can kfold on the arrays and make sequences each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**\n",
    "\n",
    "We will also train the model with the data accessible for better comparison with the simplified model. We will call this the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"callbacks += [ModelCheckpoint('./backup_model_last.hdf5'),\\n                ModelCheckpoint('./backup_model_best.hdf5', save_best_only=True)]\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TrainModel2(train_seq, val_seq, loss, opt, callbacks):\n",
    "    model_2 = get_model(train_seq.n_classes)\n",
    "    model_2.compile(loss=loss, optimizer=opt)\n",
    "    # Train neural network\n",
    "    print('Training the second model')\n",
    "    model_2.fit(train_seq,\n",
    "        epochs=70,\n",
    "        initial_epoch=0,  # If you are continuing a interrupted section change here\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_seq,\n",
    "        verbose=1)\n",
    "        \n",
    "    return model_2\n",
    "\n",
    "# Optimization settings\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss',\n",
    "                                factor=0.1,\n",
    "                                patience=7,\n",
    "                                min_lr=lr / 100),\n",
    "                EarlyStopping(monitor='val_loss', \n",
    "                            patience=9,  # Patience should be larger than the one in ReduceLROnPlateau\n",
    "                            min_delta=0.00001)]\n",
    "# Save the BEST and LAST model\n",
    "'''callbacks += [ModelCheckpoint('./backup_model_last.hdf5'),\n",
    "                ModelCheckpoint('./backup_model_best.hdf5', save_best_only=True)]'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Models**\n",
    "\n",
    "Here will test both the old model and the newly trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Model\n",
    "\n",
    "Need to choose what model I want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold\n",
    "\n",
    "K-fold procedure for validation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the second model\n",
      "Epoch 1/70\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.3142 - val_loss: 402.5722 - lr: 0.0010\n",
      "Epoch 2/70\n",
      "9/9 [==============================] - 29s 3s/step - loss: 0.2019 - val_loss: 285.7380 - lr: 0.0010\n",
      "Epoch 3/70\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.1277 - val_loss: 101.8482 - lr: 0.0010\n",
      "Epoch 4/70\n",
      "9/9 [==============================] - 29s 3s/step - loss: 0.1160 - val_loss: 27.3643 - lr: 0.0010\n",
      "Epoch 5/70\n",
      "9/9 [==============================] - 29s 3s/step - loss: 0.1005 - val_loss: 12.6471 - lr: 0.0010\n",
      "Epoch 6/70\n",
      "9/9 [==============================] - 29s 3s/step - loss: 0.0893 - val_loss: 6.8923 - lr: 0.0010\n",
      "Epoch 7/70\n",
      "9/9 [==============================] - 29s 3s/step - loss: 0.0814 - val_loss: 3.4952 - lr: 0.0010\n",
      "Epoch 8/70\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.0132"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\EDITH\\OneDrive - University of Waterloo\\School\\Masters\\Classes\\SYDE 675\\Project\\SYDE675_project\\ECG_Diagnosis_current_model.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000018?line=10'>11</a>\u001b[0m test_seq \u001b[39m=\u001b[39m ECGSequence\u001b[39m.\u001b[39mget_seq(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000018?line=11'>12</a>\u001b[0m         X_test, y_test, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000018?line=13'>14</a>\u001b[0m \u001b[39m#Train models\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000018?line=14'>15</a>\u001b[0m model_2 \u001b[39m=\u001b[39m TrainModel2(train_seq, test_seq, loss, opt, callbacks)\n",
      "\u001b[1;32mc:\\Users\\EDITH\\OneDrive - University of Waterloo\\School\\Masters\\Classes\\SYDE 675\\Project\\SYDE675_project\\ECG_Diagnosis_current_model.ipynb Cell 15'\u001b[0m in \u001b[0;36mTrainModel2\u001b[1;34m(train_seq, val_seq, loss, opt, callbacks)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000014?line=3'>4</a>\u001b[0m \u001b[39m# Train neural network\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000014?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining the second model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000014?line=5'>6</a>\u001b[0m model_2\u001b[39m.\u001b[39;49mfit(train_seq,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000014?line=6'>7</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m70\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000014?line=7'>8</a>\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,  \u001b[39m# If you are continuing a interrupted section change here\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000014?line=8'>9</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000014?line=9'>10</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_seq,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000014?line=10'>11</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/EDITH/OneDrive%20-%20University%20of%20Waterloo/School/Masters/Classes/SYDE%20675/Project/SYDE675_project/ECG_Diagnosis_current_model.ipynb#ch0000014?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model_2\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:66\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=63'>64</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_method_wrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=64'>65</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_multi_worker_mode():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=65'>66</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=67'>68</a>\u001b[0m   \u001b[39m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=68'>69</a>\u001b[0m   \u001b[39mif\u001b[39;00m dc_context\u001b[39m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:848\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=840'>841</a>\u001b[0m \u001b[39mwith\u001b[39;00m traceme\u001b[39m.\u001b[39mTraceMe(\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=841'>842</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTraceContext\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=842'>843</a>\u001b[0m     graph_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=843'>844</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=844'>845</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=845'>846</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=846'>847</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=847'>848</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m train_function(iterator)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=848'>849</a>\u001b[0m   \u001b[39m# Catch OutOfRangeError for Datasets of unknown size.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=849'>850</a>\u001b[0m   \u001b[39m# This blocks until the batch has finished executing.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=850'>851</a>\u001b[0m   \u001b[39m# TODO(b/150292341): Allow multiple async steps here.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/keras/engine/training.py?line=851'>852</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data_handler\u001b[39m.\u001b[39minferred_steps:\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:580\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=577'>578</a>\u001b[0m     xla_context\u001b[39m.\u001b[39mExit()\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=578'>579</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=579'>580</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=581'>582</a>\u001b[0m \u001b[39mif\u001b[39;00m tracing_count \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tracing_count():\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=582'>583</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_counter\u001b[39m.\u001b[39mcalled_without_tracing()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:611\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=607'>608</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=608'>609</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=609'>610</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=610'>611</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=611'>612</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=612'>613</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=613'>614</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/def_function.py?line=614'>615</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2420\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=2417'>2418</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=2418'>2419</a>\u001b[0m   graph_function, args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=2419'>2420</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_filtered_call(args, kwargs)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1661\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1646'>1647</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_filtered_call\u001b[39m(\u001b[39mself\u001b[39m, args, kwargs):\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1647'>1648</a>\u001b[0m   \u001b[39m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1648'>1649</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1649'>1650</a>\u001b[0m \u001b[39m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1658'>1659</a>\u001b[0m \u001b[39m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1659'>1660</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1660'>1661</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1661'>1662</a>\u001b[0m       (t \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m nest\u001b[39m.\u001b[39;49mflatten((args, kwargs), expand_composites\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1662'>1663</a>\u001b[0m        \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(t, (ops\u001b[39m.\u001b[39;49mTensor,\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1663'>1664</a>\u001b[0m                          resource_variable_ops\u001b[39m.\u001b[39;49mBaseResourceVariable))),\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1664'>1665</a>\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1739'>1740</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m (\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1740'>1741</a>\u001b[0m     pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1741'>1742</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1742'>1743</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1743'>1744</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1744'>1745</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1745'>1746</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1746'>1747</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1747'>1748</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1748'>1749</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1749'>1750</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=1750'>1751</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:593\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=590'>591</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=591'>592</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=592'>593</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=593'>594</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=594'>595</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=600'>601</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=601'>602</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=604'>605</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/function.py?line=605'>606</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Python38/lib/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X = tracings[:,1,1], y = labels):\n",
    "\n",
    "        X_train, X_test = tracings[train_index,:,:], tracings[test_index,:,:]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        train_seq = ECGSequence.get_seq(\n",
    "                X_train, y_train, batch_size=64)\n",
    "\n",
    "        test_seq = ECGSequence.get_seq(\n",
    "                X_test, y_test, batch_size=64)\n",
    "\n",
    "        #Train models\n",
    "        model_2 = TrainModel2(train_seq, test_seq, loss, opt, callbacks)\n",
    "\n",
    "        #Test models\n",
    "        model_1_predict = model_1.predict(test_seq,  verbose=1)\n",
    "        model_2_predict = model_2.predict(test_seq,  verbose=1)\n",
    "        model_3_predict = 1\n",
    "\n",
    "        #Find metric (use what they use)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
